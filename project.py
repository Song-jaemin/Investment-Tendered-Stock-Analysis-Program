import yfinance as yf
import pandas as pd
import numpy as np
import streamlit as st
import altair as alt
import pykrx.stock
from sklearn.ensemble import IsolationForest
from datetime import datetime, timedelta
import plotly.graph_objects as go

# 1. ì°¨íŠ¸ ë° ë°ì´í„° ìˆ˜ì§‘ ê´€ë ¨ í•¨ìˆ˜

def plot_candlestick(ticker_code, ticker_name):
    """
    ì„ íƒëœ ì¢…ëª©ì˜ 1ë…„ì¹˜ ì£¼ê°€ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ ìº”ë“¤ìŠ¤í‹± ì°¨íŠ¸ì™€ ì´ë™í‰ê· ì„ ì„ ê·¸ë¦¬ëŠ” í•¨ìˆ˜
    Args:
        ticker_code: ì¢…ëª© ì½”ë“œ
        ticker_name: ì¢…ëª© ì´ë¦„
    """
    try:
        # yfinanceë¥¼ ì´ìš©í•´ 1ë…„ì¹˜ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
        df = yf.download(ticker_code, period="1y", progress=False)
        
        if isinstance(df.columns, pd.MultiIndex):
            df.columns = df.columns.get_level_values(0)
            
        # ì´ë™í‰ê· ì„  ê³„ì‚° (20ì¼: ë‹¨ê¸° ì¶”ì„¸, 60ì¼: ì¤‘ê¸° ì¶”ì„¸)
        df['MA20'] = df['Close'].rolling(window=20).mean()
        df['MA60'] = df['Close'].rolling(window=60).mean()

        # Plotlyë¥¼ ì´ìš©í•œ ì¸í„°ë™í‹°ë¸Œ ì°¨íŠ¸ ìƒì„±
        fig = go.Figure()
        
        # ìº”ë“¤ìŠ¤í‹± ì°¨íŠ¸ ì¶”ê°€ (ì‹œê°€, ê³ ê°€, ì €ê°€, ì¢…ê°€)
        fig.add_trace(go.Candlestick(x=df.index, open=df['Open'], high=df['High'],
                                     low=df['Low'], close=df['Close'], name='ì£¼ê°€'))
        
        # ì´ë™í‰ê· ì„  ì¶”ê°€ (ì£¼í™©ìƒ‰: 20ì¼ì„ , íŒŒë€ìƒ‰: 60ì¼ì„ )
        fig.add_trace(go.Scatter(x=df.index, y=df['MA20'], line=dict(color='orange', width=1), name='20ì¼ì„ '))
        fig.add_trace(go.Scatter(x=df.index, y=df['MA60'], line=dict(color='blue', width=1), name='60ì¼ì„ '))
        
        # ì°¨íŠ¸ ë ˆì´ì•„ì›ƒ ì„¤ì •
        fig.update_layout(title=f"{ticker_name} ìƒì„¸ ë¶„ì„ (1ë…„)", height=500, xaxis_rangeslider_visible=False)
        return fig
    except:
        return None

@st.cache_data
def get_fundamental_data():
    """
    pykrx ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ KOSPI/KOSDAQ ì „ ì¢…ëª©ì˜ ìµœì‹  ì¬ë¬´ ì§€í‘œ(PER, PBR, ë°°ë‹¹ìˆ˜ìµë¥ ) ë°ì´í„° ìˆ˜ì§‘.
    * ì£¼ë§ì´ë‚˜ ê³µíœ´ì¼ì—ëŠ” ë°ì´í„°ê°€ ì—†ìœ¼ë¯€ë¡œ ìµœê·¼ 10ì¼ê°„ì˜ ë°ì´í„°ë¥¼ ì—­ì¶”ì í•˜ì—¬ ê°€ì¥ ìµœì‹  ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´.
    """
    today = datetime.now()
    
    # ìµœê·¼ 10ì¼ì„ ì—­ìˆœìœ¼ë¡œ í™•ì¸í•˜ë©° ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ” ë‚ ì§œë¥¼ íƒìƒ‰
    for days_back in range(0, 11):
        target_date = (today - timedelta(days=days_back)).strftime("%Y%m%d")
        try:
            # í•´ë‹¹ ë‚ ì§œì˜ ì‹œì¥ë³„ í€ë”ë©˜í„¸ ë°ì´í„° ìˆ˜ì§‘
            df_kospi = pykrx.stock.get_market_fundamental_by_ticker(target_date, market="KOSPI")
            df_kosdaq = pykrx.stock.get_market_fundamental_by_ticker(target_date, market="KOSDAQ")
            
            # ë‘ ì‹œì¥ ëª¨ë‘ ë°ì´í„°ê°€ ì—†ìœ¼ë©´(íœ´ì¥ì¼ ë“±) ì´ì „ ë‚ ì§œë¡œ ì´ë™
            if df_kospi.empty and df_kosdaq.empty:
                continue

            # ë°ì´í„° í•©ì¹˜ê¸°
            df_fundamental = pd.concat([df_kospi, df_kosdaq])
            
            # í•„ìš”í•œ ì»¬ëŸ¼(PER, PBR, DIV)ë§Œ ì¶”ì¶œ
            cols = ['PER', 'PBR', 'DIV']
            available_cols = [c for c in cols if c in df_fundamental.columns]
            
            if not df_fundamental.empty:
                df_result = df_fundamental[available_cols].copy()
                df_result.index = df_result.index.astype(str)
                return df_result
        except:
            continue
    return None

# 2. í˜ì´ì§€ ì„¤ì • ë° ì´ˆê¸°í™”

# ì‚¬ì´ë“œë°”ë¥¼ ê¸°ë³¸ì ìœ¼ë¡œ ìˆ¨ê¹€ ìƒíƒœ(collapsed)ë¡œ ì‹œì‘
st.set_page_config(layout="wide", page_title="íˆ¬ì ì„±í–¥ ë§ì¶¤ ë¶„ì„ê¸°", initial_sidebar_state="collapsed")

st.markdown("""
<style>
    [data-testid="stSidebar"] {display: none;}
    [data-testid="collapsedControl"] {display: none;}
</style>
""", unsafe_allow_html=True)

# Streamlit ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'step' not in st.session_state:
    st.session_state.step = 1       # í˜„ì¬ ë‹¨ê³„ (1: ì„±í–¥íŒŒì•…, 2: ì¢…ëª©ì„ íƒ, 3: ê²°ê³¼)
if 'propensity' not in st.session_state:
    st.session_state.propensity = None # íˆ¬ì ì„±í–¥ ê²°ê³¼
if 'selected_tickers' not in st.session_state:
    st.session_state.selected_tickers = [] # ì„ íƒëœ ì¢…ëª© ë¦¬ìŠ¤íŠ¸
if 'analysis_result' not in st.session_state:
    st.session_state.analysis_result = None # ë¶„ì„ ê²°ê³¼ ë°ì´í„°
if 'stock_data_prices' not in st.session_state:
    st.session_state.stock_data_prices = None # ì£¼ê°€ ë°ì´í„°
if 'fundamental_data' not in st.session_state:
    st.session_state.fundamental_data = None # ì¬ë¬´ ë°ì´í„°

# 3. ì •ì  ë°ì´í„° (ì„¹í„° ì •ë³´, ì¢…ëª© ë§¤í•‘)

# ê´€ì‹¬ ë¶„ì•¼ë³„ ì¢…ëª© ë¦¬ìŠ¤íŠ¸
sectors = {
    'IT/í”Œë«í¼': ['005930.KS', '035420.KS', '035720.KS', '032640.KS', '017670.KS', '030200.KS', '005935.KS', '066570.KS'], 
    'ë°˜ë„ì²´': ['000660.KS', '000990.KS', '009150.KS', '011070.KS', '373220.KS', '006400.KS', '003670.KS', '051910.KS'], 
    'ë°”ì´ì˜¤/í—¬ìŠ¤ì¼€ì–´': ['207940.KS', '068270.KS', '328150.KQ', '178920.KQ', '000100.KS', '128940.KS', '009290.KS', '008930.KS'], 
    'ê¸ˆìœµ': ['105560.KS', '055550.KS', '323410.KS', '000810.KS', '034730.KS', '006800.KS', '016360.KS', '039490.KS'], 
    'ìë™ì°¨': ['005380.KS', '000270.KS', '012330.KS', '018880.KS', '011790.KS', '010130.KS', '004020.KS', '017940.KS'], 
    'ë°°í„°ë¦¬/í™”í•™': ['373220.KS', '051910.KS', '096770.KS', '086520.KQ', '006400.KS', '003670.KS', '000150.KS', '004990.KS'], 
    'ì—”í„°í…Œì¸ë¨¼íŠ¸': ['352820.KS', '035900.KS', '041510.KQ', '035760.KQ', '140410.KQ', '131970.KQ', '237880.KQ', '187790.KQ'], 
    'ê²Œì„': ['251270.KS', '036570.KS', '112040.KQ', '293490.KQ', '078600.KQ', '259960.KQ', '052790.KQ', '042040.KQ']  
}

# í‹°ì»¤ë¥¼ ì¢…ëª©ëª…ìœ¼ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•œ ë§µ
ticker_name_map = {
    '005930.KS': 'ì‚¼ì„±ì „ì', '035420.KS': 'NAVER', '035720.KS': 'ì¹´ì¹´ì˜¤', '032640.KS': 'LGìœ í”ŒëŸ¬ìŠ¤', '017670.KS': 'SKí…”ë ˆì½¤', '030200.KS': 'KT', '005935.KS': 'ì‚¼ì„±ì „ììš°', '066570.KS': 'LGì „ì',
    '000660.KS': 'SKí•˜ì´ë‹‰ìŠ¤', '000990.KS': 'DBí•˜ì´í…', '009150.KS': 'ì‚¼ì„±ì „ê¸°', '011070.KS': 'LGì´ë…¸í…', '373220.KS': 'LGì—ë„ˆì§€ì†”ë£¨ì…˜', '006400.KS': 'ì‚¼ì„±SDI', '003670.KS': 'í¬ìŠ¤ì½”í“¨ì²˜ì— ', '051910.KS': 'LGí™”í•™',
    '207940.KS': 'ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤', '068270.KS': 'ì…€íŠ¸ë¦¬ì˜¨', '328150.KQ': 'ì•Œí…Œì˜¤ì  ', '178920.KQ': 'HLB', '000100.KS': 'ìœ í•œì–‘í–‰', '128940.KS': 'í•œë¯¸ì•½í’ˆ', '009290.KS': 'ê´‘ë™ì œì•½', '008930.KS': 'í•œë¯¸ì‚¬ì´ì–¸ìŠ¤',
    '105560.KS': 'KBê¸ˆìœµ', '055550.KS': 'ì‹ í•œì§€ì£¼', '323410.KS': 'ì¹´ì¹´ì˜¤ë±…í¬', '000810.KS': 'ì‚¼ì„±í™”ì¬', '034730.KS': 'SK', '006800.KS': 'ë¯¸ë˜ì—ì…‹ì¦ê¶Œ', '016360.KS': 'ì‚¼ì„±ì¦ê¶Œ', '039490.KS': 'í‚¤ì›€ì¦ê¶Œ',
    '005380.KS': 'í˜„ëŒ€ì°¨', '000270.KS': 'ê¸°ì•„', '012330.KS': 'í˜„ëŒ€ëª¨ë¹„ìŠ¤', '018880.KS': 'í•œì˜¨ì‹œìŠ¤í…œ', '011790.KS': 'SKC', '010130.KS': 'ê³ ë ¤ì•„ì—°', '004020.KS': 'í˜„ëŒ€ì œì² ', '017940.KS': 'E1',
    '096770.KS': 'SKì´ë…¸ë² ì´ì…˜', '086520.KQ': 'ì—ì½”í”„ë¡œ', '000150.KS': 'ë‘ì‚°', '004990.KS': 'ë¡¯ë°ì¼€ë¯¸ì¹¼',
    '352820.KS': 'í•˜ì´ë¸Œ', '035900.KS': 'JYP Ent.', '041510.KQ': 'ì—ìŠ¤ì— ', '035760.KQ': 'CJ ENM', '140410.KQ': 'ì™€ì´ì§€ì—”í„°í…Œì¸ë¨¼íŠ¸', '131970.KQ': 'ìŠ¤íŠœë””ì˜¤ë“œë˜ê³¤', '237880.KQ': 'í´ë˜ì‹œìŠ¤', '187790.KQ': 'í…Œí¬ìœ™',
    '251270.KS': 'ë„·ë§ˆë¸”', '036570.KS': 'í¬ë˜í”„í†¤', '112040.KQ': 'ìœ„ë©”ì´ë“œ', '293490.KQ': 'ì¹´ì¹´ì˜¤ê²Œì„ì¦ˆ', '078600.KQ': 'í„ì–´ë¹„ìŠ¤', '259960.KQ': 'ì»´íˆ¬ìŠ¤í™€ë”©ìŠ¤', '052790.KQ': 'ì•„í”„ë¦¬ì¹´TV', '042040.KQ': 'ì¼€ì´ì‚¬ì¸',
    '^KS11': 'ì½”ìŠ¤í”¼ ì§€ìˆ˜',
    '005490.KS': 'POSCOí™€ë”©ìŠ¤', '051900.KS': 'LGìƒí™œê±´ê°•', '000720.KS': 'í˜„ëŒ€ê±´ì„¤',
}

top10_kospi_names = [
    'ì‚¼ì„±ì „ì', 'SKí•˜ì´ë‹‰ìŠ¤', 'LGì—ë„ˆì§€ì†”ë£¨ì…˜', 'ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤', 'ì‚¼ì„±ì „ììš°',
    'í˜„ëŒ€ì°¨', 'ê¸°ì•„', 'POSCOí™€ë”©ìŠ¤', 'NAVER', 'LGí™”í•™'
]

# ì´ë¦„ì„ í‚¤ë¡œ, í‹°ì»¤ë¥¼ ê°’ìœ¼ë¡œ í•˜ëŠ” ì—­ë°©í–¥ ë§µ
name_ticker_map = {name: ticker for ticker, name in ticker_name_map.items()}
kospi_ticker = '^KS11'

# 4. ë¶„ì„ ë¡œì§ í•¨ìˆ˜

@st.cache_data
def get_stock_data(tickers, period="3y"):
    #ì„ íƒí•œ ì¢…ëª©ë“¤ì˜ ê³¼ê±° ì£¼ê°€ ë°ì´í„°ë¥¼ yfinanceë¡œ í•œ ë²ˆì— ê°€ì ¸ì˜´.
    try:
        raw_data = yf.download(tickers, period=period, progress=False)
        if raw_data.empty: return None
        
        # yfinance ë°ì´í„° êµ¬ì¡° ì²˜ë¦¬ (Close, Adj Close ìš°ì„ ìˆœìœ„ ì„ íƒ)
        if isinstance(raw_data.columns, pd.MultiIndex):
            try:
                close_data = raw_data.loc[:, pd.IndexSlice['Close', :]]
                close_data.columns = close_data.columns.get_level_values(1)
            except KeyError:
                close_cols = [col for col in raw_data.columns if 'Close' in col[0]]
                if not close_cols:
                    adj_close_cols = [col for col in raw_data.columns if 'Adj Close' in col[0]]
                    if adj_close_cols:
                        close_data = raw_data[adj_close_cols]
                        close_data.columns = close_data.columns.get_level_values(1)
                    else:
                        return None
                else:
                    close_data = raw_data[close_cols]
                    close_data.columns = close_data.columns.get_level_values(1)
        elif 'Close' in raw_data.columns:
            close_data = raw_data[['Close']]
            if len(tickers) == 1: close_data.columns = [tickers[0]]
        elif 'Adj Close' in raw_data.columns:
            close_data = raw_data[['Adj Close']]
            if len(tickers) == 1: close_data.columns = [tickers[0]]
        else:
            return None
        
        close_data = close_data.dropna(how='all')
        return close_data if not close_data.empty else None
    except Exception:
        return None

@st.cache_data
def check_anomalies(stock_data_series, recent_days=7, contamination=0.03):
    
    #Isolation Forest ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ì´ìƒì¹˜(ë¹„ì •ìƒì ì¸ ê¸‰ë“±ë½)ë¥¼ íƒì§€.

    if stock_data_series is None or stock_data_series.empty or stock_data_series.isnull().all():
        return False
    
    # ìˆ˜ìµë¥  ê³„ì‚° (ê°€ê²© ë³€ë™í­)
    returns = stock_data_series.pct_change().dropna()
    returns = returns.replace([np.inf, -np.inf], np.nan).dropna()
    
    if returns.empty or len(returns) < recent_days:
        return False
        
    # ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ ë°ì´í„° í˜•íƒœ ë³€í™˜
    data_for_model = returns.values.reshape(-1, 1)
    
    try:
        # Isolation Forest ëª¨ë¸ í•™ìŠµ
        model = IsolationForest(contamination=contamination, random_state=42)
        model.fit(data_for_model)
        predictions = model.predict(data_for_model)
        
        # ìµœê·¼ 7ì¼ ë‚´ì— ì´ìƒì¹˜(-1)ê°€ ìˆëŠ”ì§€ í™•ì¸
        recent_predictions = predictions[-recent_days:]
        if -1 in recent_predictions: return True
        else: return False
    except ValueError:
        return False

def analyze_stocks(stock_data, kospi_data_df):

    # ì£¼ê°€ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ìµë¥ , ë³€ë™ì„±, ìƒê´€ê³„ìˆ˜ ë“±ì„ ê³„ì‚°í•˜ê³  ì´ìƒì¹˜ íƒì§€ ê²°ê³¼ë¥¼ ì¢…í•©.

    if stock_data is None or kospi_data_df is None or stock_data.empty or kospi_data_df.empty: return None
    
    returns = stock_data.pct_change().dropna(how='all')
    kospi_returns = kospi_data_df.iloc[:, 0].pct_change().dropna()
    
    if returns.empty or kospi_returns.empty: return None
    analysis = {}
    
    # ì½”ìŠ¤í”¼ ë°ì´í„°ì™€ ë‚ ì§œ ì¸ë±ìŠ¤ ë§ì¶”ê¸°
    common_index = returns.index.intersection(kospi_returns.index)
    if common_index.empty: return None
    returns = returns.loc[common_index]
    kospi_returns = kospi_returns.loc[common_index]

    for stock_ticker in returns.columns:
        if returns[stock_ticker].isnull().all(): continue
        stock_returns = returns[stock_ticker].dropna()
        if stock_returns.empty: continue
        
        # ì—°ìœ¨í™”ëœ ì§€í‘œ ê³„ì‚° (1ë…„ ê±°ë˜ì¼ìˆ˜=252ì¼)
        avg_return = stock_returns.mean() * 252 # ì—°í‰ê·  ìˆ˜ìµë¥ 
        volatility = stock_returns.std() * np.sqrt(252) # ì—° ë³€ë™ì„±
        correlation = stock_returns.corr(kospi_returns) # ì‹œì¥ ìƒê´€ê³„ìˆ˜
        max_daily_gain = stock_returns.max()
        max_daily_loss = stock_returns.min()
        
        # ì´ìƒì¹˜ íƒì§€ ìˆ˜í–‰
        original_price_series = stock_data[stock_ticker]
        has_anomaly = check_anomalies(original_price_series, recent_days=7)

        analysis[stock_ticker] = {
            'ì—°í‰ê·  ìˆ˜ìµë¥ ': avg_return,
            'ì—° ë³€ë™ì„±': volatility,
            'ì½”ìŠ¤í”¼ ìƒê´€ê³„ìˆ˜': correlation,
            'ì¼ì¼ ìµœëŒ€ ìƒìŠ¹ë¥ ': max_daily_gain,
            'ì¼ì¼ ìµœëŒ€ í•˜ë½ë¥ ': max_daily_loss,
            'ğŸš¨ ìµœê·¼ 7ì¼ë‚´ ì´ìƒì‹ í˜¸': has_anomaly
        }
    return analysis

@st.cache_data
def get_pykrx_name_map():
    # pykrxë¥¼ í†µí•´ ì „ì²´ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì™€ì„œ ê²€ìƒ‰ìš© ë§µ ìƒì„±
    pykrx_name_map = {}
    for market in ["KOSPI", "KOSDAQ"]:
        suffix = ".KS" if market == "KOSPI" else ".KQ"
        tickers = pykrx.stock.get_market_ticker_list(market=market)
        for t in tickers:
            name = pykrx.stock.get_market_ticker_name(t)
            if name: pykrx_name_map[name] = f"{t}{suffix}"
    return pykrx_name_map

# 5. UI í˜ì´ì§€ êµ¬ì„± í•¨ìˆ˜ (Step 1, 2, 3)

def page_step1_propensity():
    # Step 1: íˆ¬ì ì„±í–¥ ì„¤ë¬¸ì¡°ì‚¬ í˜ì´ì§€
    st.title("ğŸ¯ Step 1. íˆ¬ì ì„±í–¥ ë¶„ì„")
    st.markdown("ë‹¤ìŒ 5ê°€ì§€ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.")
    st.write("")

    with st.container(border=True):
        # ì„¤ë¬¸ ë¬¸í•­
        q1 = st.radio("1. ë‹¹ì‹ ì˜ ì—°ë ¹ì€ ì–´ë–»ê²Œ ë©ë‹ˆê¹Œ?", ['19ì„¸ì´í•˜', '20 ~ 40ì„¸', '41 ~ 50ì„¸', '51 ~ 60ì„¸', '60ì„¸ì´ìƒ'], key='q1')
        st.write("")
        q2 = st.radio("2. íˆ¬ìí•˜ê³ ì í•˜ëŠ” ìê¸ˆì˜ íˆ¬ì ê°€ëŠ¥ ê¸°ê°„ì€ ì–¼ë§ˆë‚˜ ë©ë‹ˆê¹Œ?", ['6ê°œì›” ì´ë‚´', '6ê°œì›” ~ 1ë…„ ì´ë‚´', '1ë…„ ~ 2ë…„ ì´ë‚´', '2ë…„ ~ 3ë…„ ì´ë‚´', '3ë…„ ì´ìƒ'], key='q2')
        st.write("")
        q3 = st.radio("3. í˜„ì¬ íˆ¬ìí•˜ê³ ì í•˜ëŠ” ìê¸ˆì€ ì „ì²´ ê¸ˆìœµìì‚° ì¤‘ ì–´ëŠ ì •ë„ì˜ ë¹„ì¤‘ì„ ì°¨ì§€í•©ë‹ˆê¹Œ?", ['10% ì´ë‚´', '10% ~ 20% ì´ë‚´', '20% ~ 30% ì´ë‚´', '30% ~ 40% ì´ë‚´', '40% ì´ˆê³¼'], key='q3')
        st.write("")
        q4 = st.radio("4. ë‹¤ìŒ ì¤‘ ë‹¹ì‹ ì˜ ìˆ˜ì…ì›ì„ ê°€ì¥ ì˜ ë‚˜íƒ€ë‚´ê³  ìˆëŠ” ê²ƒì€ ì–´ëŠ ê²ƒì…ë‹ˆê¹Œ?", [
                'í˜„ì¬ ì¼ì •í•œ ìˆ˜ì…ì´ ë°œìƒí•˜ê³  ìˆìœ¼ë©°, í–¥í›„ í˜„ì¬ ìˆ˜ì¤€ì„ ìœ ì§€í•˜ê±°ë‚˜ ì¦ê°€í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒ',
                'í˜„ì¬ ì¼ì •í•œ ìˆ˜ì…ì´ ë°œìƒí•˜ê³  ìˆìœ¼ë‚˜, í–¥í›„ ê°ì†Œí•˜ê±°ë‚˜ ë¶ˆì•ˆì •í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒ',
                'í˜„ì¬ ì¼ì •í•œ ìˆ˜ì…ì›ì´ ì—†ìœ¼ë©°, ì—°ê¸ˆì´ ì£¼ ìˆ˜ì…ì›ì„'
            ], key='q4')
        st.write("")
        q5 = st.radio("5. ë§Œì•½ íˆ¬ìì›ê¸ˆì— ì†ì‹¤ì´ ë°œìƒí•  ê²½ìš° ë‹¤ìŒ ì¤‘ ê°ìˆ˜í•  ìˆ˜ ìˆëŠ” ì†ì‹¤ ìˆ˜ì¤€ì€ ì–´ëŠ ê²ƒì…ë‹ˆê¹Œ?", [
                'ë¬´ìŠ¨ ì¼ì´ ìˆì–´ë„ íˆ¬ìì›ê¸ˆì€ ë³´ì „ë˜ì–´ì•¼ í•œë‹¤.',
                '10% ë¯¸ë§Œê¹Œì§€ëŠ” ì†ì‹¤ì„ ê°ìˆ˜ í•  ìˆ˜ ìˆì„ ê²ƒ ê°™ë‹¤.',
                '20% ë¯¸ë§Œê¹Œì§€ëŠ” ì†ì‹¤ì„ ê°ìˆ˜ í•  ìˆ˜ ìˆì„ ê²ƒ ê°™ë‹¤.',
                'ê¸°ëŒ€ìˆ˜ìµì´ ë†’ë‹¤ë©´ ìœ„í—˜ì´ ë†’ì•„ë„ ìƒê´€í•˜ì§€ ì•Šê² ë‹¤.'
            ], key='q5')

    # ì ìˆ˜ ê³„ì‚° ë¡œì§ (ê° ë‹µë³€ì— ê°€ì¤‘ì¹˜ ë¶€ì—¬)
    score = 0
    score += {'19ì„¸ì´í•˜': 5, '20 ~ 40ì„¸': 5, '41 ~ 50ì„¸': 4, '51 ~ 60ì„¸': 3, '60ì„¸ì´ìƒ': 2}[q1]
    score += {'6ê°œì›” ì´ë‚´': 1, '6ê°œì›” ~ 1ë…„ ì´ë‚´': 2, '1ë…„ ~ 2ë…„ ì´ë‚´': 3, '2ë…„ ~ 3ë…„ ì´ë‚´': 4, '3ë…„ ì´ìƒ': 5}[q2]
    score += {'10% ì´ë‚´': 1, '10% ~ 20% ì´ë‚´': 2, '20% ~ 30% ì´ë‚´': 3, '30% ~ 40% ì´ë‚´': 4, '40% ì´ˆê³¼': 5}[q3]
    score += {'í˜„ì¬ ì¼ì •í•œ ìˆ˜ì…ì´ ë°œìƒí•˜ê³  ìˆìœ¼ë©°, í–¥í›„ í˜„ì¬ ìˆ˜ì¤€ì„ ìœ ì§€í•˜ê±°ë‚˜ ì¦ê°€í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒ': 5, 
              'í˜„ì¬ ì¼ì •í•œ ìˆ˜ì…ì´ ë°œìƒí•˜ê³  ìˆìœ¼ë‚˜, í–¥í›„ ê°ì†Œí•˜ê±°ë‚˜ ë¶ˆì•ˆì •í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒ': 3, 
              'í˜„ì¬ ì¼ì •í•œ ìˆ˜ì…ì›ì´ ì—†ìœ¼ë©°, ì—°ê¸ˆì´ ì£¼ ìˆ˜ì…ì›ì„': 1}[q4]
    score += {'ë¬´ìŠ¨ ì¼ì´ ìˆì–´ë„ íˆ¬ìì›ê¸ˆì€ ë³´ì „ë˜ì–´ì•¼ í•œë‹¤.': 0, 
              '10% ë¯¸ë§Œê¹Œì§€ëŠ” ì†ì‹¤ì„ ê°ìˆ˜ í•  ìˆ˜ ìˆì„ ê²ƒ ê°™ë‹¤.': 4, 
              '20% ë¯¸ë§Œê¹Œì§€ëŠ” ì†ì‹¤ì„ ê°ìˆ˜ í•  ìˆ˜ ìˆì„ ê²ƒ ê°™ë‹¤.': 8, 
              'ê¸°ëŒ€ìˆ˜ìµì´ ë†’ë‹¤ë©´ ìœ„í—˜ì´ ë†’ì•„ë„ ìƒê´€í•˜ì§€ ì•Šê² ë‹¤.': 12}[q5]

    # ë¶„ì„ ì™„ë£Œ ë²„íŠ¼
    if st.button("ì„±í–¥ ë¶„ì„ ì™„ë£Œ ë° ë‹¤ìŒ ë‹¨ê³„ ğŸ‘‰", type="primary", use_container_width=True):
        # ì ìˆ˜ì— ë”°ë¥¸ ì„±í–¥ ë¶„ë¥˜
        if score <= 12: propensity = 'ì•ˆì •í˜•'
        elif score <= 18: propensity = 'ì•ˆì •ì¶”êµ¬í˜•'
        elif score <= 24: propensity = 'ìœ„í—˜ì¤‘ë¦½í˜•'
        else: propensity = 'ì ê·¹íˆ¬ìí˜•'
        
        # ì„¸ì…˜ì— ê²°ê³¼ ì €ì¥ ë° ë‹¤ìŒ ë‹¨ê³„ë¡œ ì´ë™
        st.session_state.propensity = propensity
        st.session_state.step = 2
        st.rerun()


def page_step2_selection():
    #Step 2: ë¶„ì„í•  ì¢…ëª© ì„ íƒ í˜ì´ì§€

    st.title("ğŸ” Step 2. ê´€ì‹¬ ì¢…ëª© ì„ íƒ")
    st.info(f"ë‹¹ì‹ ì˜ íˆ¬ì ì„±í–¥ì€ **[{st.session_state.propensity}]** ì…ë‹ˆë‹¤.")
    st.write("ë¶„ì„í•˜ê³  ì‹¶ì€ ì¢…ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")

    with st.container(border=True):
        analysis_type = st.radio("ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ì¢…ëª©ì„ ì°¾ìœ¼ì‹œê² ìŠµë‹ˆê¹Œ?", 
                                 ('ê´€ì‹¬ ë¶„ì•¼ë³„ ë³´ê¸°', 'KOSPI ìƒìœ„ 10', 'ì§ì ‘ ê²€ìƒ‰'), 
                                 horizontal=True)
        
        selected_tickers = []
        
        # 1. ë¶„ì•¼ë³„ ì„ íƒ
        if analysis_type == 'ê´€ì‹¬ ë¶„ì•¼ë³„ ë³´ê¸°':
            sector_list = list(sectors.keys())
            selected_sector = st.selectbox("ê´€ì‹¬ ë¶„ì•¼ ì„ íƒ", sector_list)
            selected_tickers = sectors.get(selected_sector, [])
            selected_names = [ticker_name_map.get(t, t) for t in selected_tickers]
            st.success(f"**ì„ íƒëœ ë¶„ì•¼:** {selected_sector} ({len(selected_names)}ê°œ ì¢…ëª©)")
            
        # 2. ì½”ìŠ¤í”¼ Top 10 ì„ íƒ
        elif analysis_type == 'KOSPI ìƒìœ„ 10':
            selected_stocks_names = st.multiselect("ë¶„ì„í•  ì¢…ëª© ì„ íƒ", top10_kospi_names, default=top10_kospi_names)
            if selected_stocks_names:
                selected_tickers = [name_ticker_map[name] for name in selected_stocks_names if name in name_ticker_map]
            
        # 3. ì§ì ‘ ê²€ìƒ‰ (ì „ì²´ ì¢…ëª© ë¡œë“œ í•„ìš”)
        elif analysis_type == 'ì§ì ‘ ê²€ìƒ‰':
            try:
                if 'pykrx_map' not in st.session_state:
                    with st.spinner("ì „ì²´ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                        st.session_state.pykrx_map = get_pykrx_name_map()
                
                pykrx_map = st.session_state.pykrx_map
                available_names = sorted(list(pykrx_map.keys()))
                selected_names = st.multiselect("ì¢…ëª©ëª… ê²€ìƒ‰", available_names)
                
                if selected_names:
                    for name in selected_names:
                        yfinance_ticker = pykrx_map.get(name)
                        if yfinance_ticker:
                            selected_tickers.append(yfinance_ticker)
                            # ìƒˆë¡œìš´ ì¢…ëª©ì´ë©´ ë§µì— ì¶”ê°€
                            if yfinance_ticker not in ticker_name_map:
                                ticker_name_map[yfinance_ticker] = name
            except Exception as e:
                st.error(f"ì¢…ëª© ë¡œë“œ ì‹¤íŒ¨: {e}")

    # í•˜ë‹¨ ë²„íŠ¼ (ì´ì „/ë¶„ì„ì‹¤í–‰)
    col1, col2 = st.columns([1, 1])
    with col1:
        if st.button("ğŸ‘ˆ ì´ì „ ë‹¨ê³„", use_container_width=True):
            st.session_state.step = 1
            st.rerun()
    with col2:
        if st.button("ë°ì´í„° ë¶„ì„ ì‹¤í–‰ ğŸš€", type="primary", use_container_width=True):
            if not selected_tickers:
                st.warning("ë¶„ì„í•  ì¢…ëª©ì„ ìµœì†Œ 1ê°œ ì´ìƒ ì„ íƒí•´ì£¼ì„¸ìš”.")
            else:
                with st.spinner("ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                    fundamental_df = get_fundamental_data()
                    st.session_state.fundamental_data = fundamental_df

                    # ê°€ê²© ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ì„ íƒì¢…ëª© + ì½”ìŠ¤í”¼ì§€ìˆ˜)
                    all_tickers_to_download = list(set(selected_tickers + [kospi_ticker]))
                    stock_data_full = get_stock_data(all_tickers_to_download)

                    if stock_data_full is not None and not stock_data_full.empty:
                        if kospi_ticker in stock_data_full.columns:
                            # ì½”ìŠ¤í”¼ ë°ì´í„° ë¶„ë¦¬
                            kospi_data = stock_data_full[[kospi_ticker]]
                            stock_data_prices = stock_data_full.drop(columns=[kospi_ticker], errors='ignore')

                            if not stock_data_prices.empty:
                                # ë¶„ì„ ì‹¤í–‰
                                analysis_result = analyze_stocks(stock_data_prices, kospi_data)
                                st.session_state.analysis_result = analysis_result
                                st.session_state.stock_data_prices = stock_data_prices
                                st.session_state.step = 3
                                st.rerun()
                            else:
                                st.error("ì„ íƒí•œ ì¢…ëª©ì˜ ê°€ê²© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            st.error("ì§€ìˆ˜ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨.")
                    else:
                        st.error("ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨.")


def page_step3_result():
    #Step 3: ë¶„ì„ ê²°ê³¼ ì¶œë ¥ í˜ì´ì§€

    propensity = st.session_state.propensity
    analysis = st.session_state.analysis_result
    stock_data_prices = st.session_state.stock_data_prices
    fundamental_data = st.session_state.fundamental_data

    st.title("ğŸ“Š Step 3. ë¶„ì„ ê²°ê³¼ ë¦¬í¬íŠ¸")
    
    # ì„±í–¥ë³„ ê°€ì´ë“œ í…ìŠ¤íŠ¸ ë° ì •ë ¬ ê¸°ì¤€ ì„¤ì •
    guide_text = ""
    if propensity == 'ì•ˆì •í˜•':
        guide_text = """
        **ğŸ“‹ ì•ˆì •í˜• íˆ¬ìì ê°€ì´ë“œ:**\n
        ê·€í•˜ëŠ” ì›ê¸ˆ ë³´ì¡´ì„ ìµœìš°ì„ ìœ¼ë¡œ í•˜ëŠ” íˆ¬ììì…ë‹ˆë‹¤. 
        ë‹¨ê¸°ì ì¸ ì‹œì„¸ ì°¨ìµë³´ë‹¤ëŠ” ì˜ˆê¸ˆ ê¸ˆë¦¬ ìˆ˜ì¤€ + Î± ì˜ ì•ˆì •ì ì¸ ìˆ˜ìµì„ ì¶”êµ¬í•©ë‹ˆë‹¤.\n
        **ì¶”ì²œ ì „ëµ:** 
        - ë³€ë™ì„±ì´ ë§¤ìš° ë‚®ê³  ì¬ë¬´êµ¬ì¡°ê°€ íƒ„íƒ„í•œ ëŒ€í˜• ìš°ëŸ‰ì£¼ ìœ„ì£¼
        - ë°°ë‹¹ ìˆ˜ìµë¥ ì´ ë†’ì€ ì¢…ëª©(DIV)ì— ì£¼ëª©í•˜ì„¸ìš”.
        """
        sort_col = 'ì—° ë³€ë™ì„±'
        ascending_sort = True
        
    elif propensity == 'ì•ˆì •ì¶”êµ¬í˜•':
        guide_text = """
        **ğŸ“‹ ì•ˆì •ì¶”êµ¬í˜• íˆ¬ìì ê°€ì´ë“œ:**\n
        ê·€í•˜ëŠ” ì›ê¸ˆì˜ ì†ì‹¤ì€ ìµœì†Œí™”í•˜ë©´ì„œë„, ì˜ˆê¸ˆë³´ë‹¤ëŠ” ë†’ì€ ìˆ˜ìµì„ ê¸°ëŒ€í•©ë‹ˆë‹¤.
        ì•½ê°„ì˜ ë³€ë™ì„±ì€ ê°ë‚´í•  ìˆ˜ ìˆì§€ë§Œ í° í•˜ë½ì€ í”¼í•˜ê³  ì‹¶ì–´í•©ë‹ˆë‹¤.\n
        **ì¶”ì²œ ì „ëµ:** 
        - ì‹¤ì ì´ ê¾¸ì¤€íˆ ìƒìŠ¹í•˜ëŠ” ìš°ëŸ‰ì£¼ ë¶„ì‚° íˆ¬ì
        - PBRì´ ë‚®ì•„ ì €í‰ê°€ëœ ì¢…ëª©ì„ ì°¾ì•„ë³´ì„¸ìš”.
        """
        sort_col = 'ì—° ë³€ë™ì„±' 
        ascending_sort = True
        
    elif propensity == 'ìœ„í—˜ì¤‘ë¦½í˜•':
        guide_text = """
        **ğŸ“‹ ìœ„í—˜ì¤‘ë¦½í˜• íˆ¬ìì ê°€ì´ë“œ:**\n
        ê·€í•˜ëŠ” ìˆ˜ìµì„ ìœ„í•´ ì–´ëŠ ì •ë„ì˜ ìœ„í—˜(ì›ê¸ˆ ì†ì‹¤ ê°€ëŠ¥ì„±)ì„ ì¶©ë¶„íˆ ê°ìˆ˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        ì‹œì¥ í‰ê·  ì´ìƒì˜ ìˆ˜ìµë¥ ì„ ëª©í‘œë¡œ í•˜ë©°, ì£¼ì‹ ì‹œì¥ì˜ ë“±ë½ì„ ì´í•´í•©ë‹ˆë‹¤.\n
        **ì¶”ì²œ ì „ëµ:** 
        - ì„±ì¥ ê°€ëŠ¥ì„±ì´ ë†’ì€ ì„¹í„°(IT, ë°˜ë„ì²´ ë“±) ì£¼ë„ì£¼ íˆ¬ì
        - ì—°í‰ê·  ìˆ˜ìµë¥ ê³¼ PER ì§€í‘œë¥¼ ê· í˜• ìˆê²Œ ê³ ë ¤í•˜ì„¸ìš”.
        """
        sort_col = 'ì—°í‰ê·  ìˆ˜ìµë¥ '
        ascending_sort = False
        
    else: # ì ê·¹íˆ¬ìí˜•
        guide_text = """
        **ğŸ“‹ ì ê·¹íˆ¬ìí˜• íˆ¬ìì ê°€ì´ë“œ:**\n
        ê·€í•˜ëŠ” ë†’ì€ ìˆ˜ìµì„ ìœ„í•´ì„œë¼ë©´ ì›ê¸ˆì˜ ìƒë‹¹ ë¶€ë¶„ ì†ì‹¤ ìœ„í—˜ë„ ê°ìˆ˜í•˜ëŠ” ê³µê²©ì ì¸ íˆ¬ììì…ë‹ˆë‹¤.
        ë‹¨ê¸°ì ì¸ ë³€ë™ì„±ì„ ê¸°íšŒë¡œ í™œìš©í•˜ë©° ì ê·¹ì ìœ¼ë¡œ ë§¤ë§¤ì— ì„í•©ë‹ˆë‹¤.\n
        **ì¶”ì²œ ì „ëµ:** 
        - ë†’ì€ ë³€ë™ì„±ì„ ê°€ì§„ ì„±ì¥ì£¼, í…Œë§ˆì£¼ íŠ¸ë ˆì´ë”©
        - ìµœê·¼ ê±°ë˜ëŸ‰ì´ ê¸‰ì¦í•˜ê±°ë‚˜ ì´ìƒ ì‹ í˜¸ê°€ ê°ì§€ëœ ì¢…ëª©ë„ ì ê·¹ ê²€í†  (ë‹¨, ë¦¬ìŠ¤í¬ ê´€ë¦¬ í•„ìˆ˜)
        """
        sort_col = 'ì—°í‰ê·  ìˆ˜ìµë¥ '
        ascending_sort = False

    st.info(guide_text)
    
    if not analysis:
        st.error("ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 1. 3ë…„ ìˆ˜ìµë¥  ë¹„êµ ì°¨íŠ¸ (ì •ê·œí™”)
    st.subheader("ğŸ“ˆ 3ë…„ê°„ ì£¼ê°€ ìˆ˜ìµë¥  ì¶”ì´ (ë¹„êµ)")
    if stock_data_prices is not None:
        price_df_to_plot = stock_data_prices.copy()
        price_df_to_plot.columns = price_df_to_plot.columns.map(ticker_name_map.get)
        try:
            # ì‹œì‘ì ì„ 100ìœ¼ë¡œ ë§ì¶”ì–´ ë¹„êµ (ì •ê·œí™”)
            normalized_df = (price_df_to_plot.fillna(method='bfill') / price_df_to_plot.fillna(method='bfill').iloc[0]) * 100
            st.line_chart(normalized_df, use_container_width=True)
        except Exception:
            st.warning("ì°¨íŠ¸ë¥¼ ê·¸ë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    st.markdown("---")

    # 2. ë¶„ì„ ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ìƒì„± ë° ë³‘í•©
    df = pd.DataFrame.from_dict(analysis, orient='index')
    
    # ì¬ë¬´ ì •ë³´(PER, PBR ë“±) ë³‘í•©
    if fundamental_data is not None and not fundamental_data.empty:
        df['ticker_clean'] = df.index.map(lambda x: str(x).split('.')[0])
        try:
            df = df.reset_index()
            # Left Join ìˆ˜í–‰
            df = pd.merge(df, fundamental_data, left_on='ticker_clean', right_index=True, how='left')
            df = df.set_index('index')
            df = df.drop(columns=['ticker_clean'], errors='ignore')
        except Exception as e:
            st.warning(f"ì¬ë¬´ ì •ë³´ ë³‘í•© ì‹¤íŒ¨: {e}")

    # ì¢…ëª©ëª… ë° ë§í¬ ìƒì„±
    df['ì¢…ëª©ëª…'] = df.index.map(lambda x: ticker_name_map.get(x, x))
    df['ìƒì„¸ì •ë³´'] = df.index.map(lambda x: f"https://finance.naver.com/item/main.naver?code={x.split('.')[0]}")
    df = df.set_index('ì¢…ëª©ëª…')

    # ì„±í–¥ì— ë§ê²Œ ë°ì´í„° ì •ë ¬
    df_sorted = df.sort_values(by=sort_col, ascending=ascending_sort)

    anomaly_stocks_df = df[df['ğŸš¨ ìµœê·¼ 7ì¼ë‚´ ì´ìƒì‹ í˜¸'] == True]
    
    # 1ìˆœìœ„ ì¶”ì²œ ì¢…ëª© í‘œì‹œ
    best_stock = df_sorted.index[0] if not df_sorted.empty else "ì—†ìŒ"
    st.success(f"ğŸ† 1ìˆœìœ„ ì¶”ì²œ ì¢…ëª©: **{best_stock}**")

    # í…Œì´ë¸” ì»¬ëŸ¼ í¬ë§· ì„¤ì •
    column_config = {
        "ìƒì„¸ì •ë³´": st.column_config.LinkColumn("ìì„¸íˆ ë³´ê¸°", display_text="ë°”ë¡œê°€ê¸°"),
        "PER": st.column_config.NumberColumn("PER(ì£¼ê°€ìˆ˜ìµë¥ )", format="%.2f"),
        "PBR": st.column_config.NumberColumn("PBR(ì£¼ê°€ìˆœìì‚°ë¹„ìœ¨)", format="%.2f"),
        "DIV": st.column_config.NumberColumn("ë°°ë‹¹ìˆ˜ìµë¥ ", format="%.2f%%"),
    }
    base_formatter = {
        'ì—°í‰ê·  ìˆ˜ìµë¥ ': '{:.2%}', 'ì—° ë³€ë™ì„±': '{:.2%}', 'ì½”ìŠ¤í”¼ ìƒê´€ê³„ìˆ˜': '{:.2f}',
        'ì¼ì¼ ìµœëŒ€ ìƒìŠ¹ë¥ ': '{:.2%}', 'ì¼ì¼ ìµœëŒ€ í•˜ë½ë¥ ': '{:.2%}',
    }
    
    # í¬íŠ¸í´ë¦¬ì˜¤ í…Œì´ë¸” ì¶œë ¥
    st.subheader(f"ğŸ“„ ë§ì¶¤ í¬íŠ¸í´ë¦¬ì˜¤ ({propensity})")
    
    # í‘œì‹œìš© ë°ì´í„°í”„ë ˆì„ ë³µì‚¬ ë° í…ìŠ¤íŠ¸ ì¹˜í™˜
    df_display = df_sorted.copy()
    df_display['ğŸš¨ ìµœê·¼ 7ì¼ë‚´ ì´ìƒì‹ í˜¸'] = df_display['ğŸš¨ ìµœê·¼ 7ì¼ë‚´ ì´ìƒì‹ í˜¸'].apply(lambda x: "ğŸ”¥ ê°ì§€ë¨" if x else "âœ… ì •ìƒ")
    
    st.dataframe(df_display.style.format(base_formatter), column_config=column_config, use_container_width=True)

    # ì´ìƒì¹˜ ê°ì§€ ì¢…ëª© ë³„ë„ í‘œì‹œ
    if not anomaly_stocks_df.empty:
        st.subheader("ğŸš¨ íˆ¬ì ìœ ì˜ í•„ìš” (ì´ìƒ ê¸‰ë“±ë½ ê°ì§€)")
        st.write("ìµœê·¼ 7ì¼ ì´ë‚´ì— í†µê³„ì ìœ¼ë¡œ ë¹„ì •ìƒì ì¸ ì£¼ê°€ íë¦„ì´ ê°ì§€ëœ ì¢…ëª©ì…ë‹ˆë‹¤.")
        anomaly_display = anomaly_stocks_df.copy()
        anomaly_display['ğŸš¨ ìµœê·¼ 7ì¼ë‚´ ì´ìƒì‹ í˜¸'] = "ğŸ”¥ ê°ì§€ë¨"
        st.dataframe(
            anomaly_display.sort_values(by='ì—° ë³€ë™ì„±', ascending=False).style.format(base_formatter), 
            column_config=column_config, 
            use_container_width=True
        )

    st.markdown("---")
    
    # ì°¨íŠ¸ ì„¹ì…˜
    st.subheader("ğŸ” ìƒì„¸ ì°¨íŠ¸ ")
    ticker_list = list(analysis.keys())
    name_list = [ticker_name_map.get(t, t) for t in ticker_list]
    selected_name = st.selectbox("ì°¨íŠ¸ë¥¼ í™•ì¸í•  ì¢…ëª© ì„ íƒ:", name_list)
    
    if selected_name:
        # ì„ íƒëœ ì´ë¦„ìœ¼ë¡œ í‹°ì»¤ ì°¾ê¸°
        selected_ticker = [k for k, v in ticker_name_map.items() if v == selected_name][0]
        with st.spinner("ì°¨íŠ¸ ê·¸ë¦¬ëŠ” ì¤‘..."):
            fig = plot_candlestick(selected_ticker, selected_name)
            if fig:
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("ì°¨íŠ¸ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    st.write("")
    with st.container(border=True):
        st.markdown("#### ğŸ’¡ íˆ¬ì ì „ í•„ë…ì‚¬í•­")
        st.markdown("""<small>ë³¸ ì„œë¹„ìŠ¤ëŠ” ê³¼ê±° ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤. ëª¨ë“  íˆ¬ìì˜ ì±…ì„ì€ íˆ¬ìì ë³¸ì¸ì—ê²Œ ìˆìŠµë‹ˆë‹¤.</small>""", unsafe_allow_html=True)

    if st.button("ğŸ”„ ì²˜ìŒë¶€í„° ë‹¤ì‹œ í•˜ê¸°", use_container_width=True):
        st.session_state.step = 1
        st.session_state.selected_tickers = []
        st.rerun()

# 6. ë©”ì¸ ì‹¤í–‰ ì»¨íŠ¸ë¡¤ëŸ¬

def main():
    # í˜„ì¬ ë‹¨ê³„(step)ì— ë”°ë¼ í•´ë‹¹ í˜ì´ì§€ í•¨ìˆ˜ë¥¼ í˜¸ì¶œ
    if st.session_state.step == 1:
        page_step1_propensity()
    elif st.session_state.step == 2:
        page_step2_selection()
    elif st.session_state.step == 3:
        page_step3_result()

if __name__ == "__main__":
    main()